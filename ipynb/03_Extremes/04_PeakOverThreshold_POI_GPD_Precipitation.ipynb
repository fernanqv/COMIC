{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peaks Over Threshold (POT) - Poisson & Generalized Pareto distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precipitation database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. Input Precipitation](#1)\n",
    "\t* [1.1. Load Dataset](#11)  \n",
    "\t* [1.2. Data Visualization: Time Series](#12)     \n",
    "\t* [1.3. Data Visualization: Histograms](#13)     \n",
    "    \n",
    "* [2. Peaks Over Threshold (POT)](#2)\n",
    "\t* [2.1. Calculate POT](#21)\n",
    "    * [2.2. Data visualization - Daily and POT precipitation](#22)\n",
    "\n",
    "* [3. Fit POT Frequency and Intensity](#3)\n",
    "\t* [3.1 Fit POT Frequency to Poisson disribution](#31)\n",
    "\t* [3.2 Fit POT Intensity to Generalized Pareto disribution](#32)\n",
    "    \n",
    "* [4. Simulate Precipitation Extremes](#4)\n",
    "\t* [4.1. Use Frequency and Intensity distributions (Poisson and Generalized Pareto) to generate Precipitation Extremes](#41)\n",
    "    * [4.2. Plot return period](#42)\n",
    "    \n",
    "<hr size=\"5\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "from numpy.random import multivariate_normal\n",
    "from scipy.stats import poisson, genpareto\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Input Precipitation <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load Dataset <a class=\"anchor\" id=\"11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "p_db = op.join(os.getcwd(), '..', '..', 'data', 'Precipitation_Cantabria')\n",
    "\n",
    "# read database precipitation (xls file)\n",
    "p_dat = op.join(p_db, '1083e_R.xls')\n",
    "\n",
    "data = pd.read_excel(\n",
    "    p_dat,\n",
    "    header = None, \n",
    "    names = ['Precipitation']\n",
    ")\n",
    "\n",
    "# set dataframe time index\n",
    "data.index =  np.arange('1970-10-01', '2003-10-01', dtype='datetime64[D]')\n",
    "data.index.name = 'time'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data Visualization: Time Series <a class=\"anchor\" id=\"12\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Data Visualization - Histograms <a class=\"anchor\" id=\"13\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=['Count', 'Probability Density'],\n",
    ")\n",
    "fig.append_trace(\n",
    "    go.Histogram(x = data['Precipitation'], nbinsx = 50), \n",
    "    1, 1,\n",
    ")\n",
    "fig.append_trace( \n",
    "    go.Histogram(x = data['Precipitation'], nbinsx = 50, histnorm='probability density'), \n",
    "    1, 2\n",
    ")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Peaks Over Threshold (POT) <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dataset hydrologic year (10-01)\n",
    "data_month = pd.DatetimeIndex(data.index).month\n",
    "data_day = pd.DatetimeIndex(data.index).day\n",
    "\n",
    "# generate hydrologic year indexes\n",
    "split = np.where((data_month==10) & (data_day==1))[0]\n",
    "yh = np.zeros(len(data))\n",
    "for c, v in enumerate(split[:-1]):\n",
    "    yh[split[c]:split[c+1]] = 1970 + c\n",
    "yh[split[-1]:] = 1970+len(split)-1\n",
    "\n",
    "data_index_hydro = yh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Calculate POT <a class=\"anchor\" id=\"21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "th = np.percentile(data.Precipitation, 98)  # threshold \n",
    "ie = 5   # days between independent peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate data over threshold\n",
    "data_pot = data.loc[data['Precipitation'] >= th]\n",
    "ix_hydro_pot = data_index_hydro[data['Precipitation'] >= th]\n",
    "\n",
    "\n",
    "ix_space = np.diff(data_pot.index).astype('timedelta64[D]').astype(int)\n",
    "ix_space = list(ix_space) + [ie] # include last event\n",
    "\n",
    "# Get independent peaks\n",
    "idx = []\n",
    "for nt in np.where(ix_space)[0]:\n",
    "    day = data_pot.index[nt]\n",
    "    rangeday = np.arange(day-datetime.timedelta(days=ie), day+datetime.timedelta(days=ie), datetime.timedelta(days=1))\n",
    "    if data_pot.iloc[nt].values == np.max(data.loc[rangeday]).values:\n",
    "        idx.append(nt)\n",
    "\n",
    "data_pot = data_pot.iloc[idx]\n",
    "ix_hydro_pot = ix_hydro_pot[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precipitation Annual Maxima time series\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = data.index, y = data['Precipitation'],\n",
    "        mode ='lines', name = 'Historic',\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = data_pot.index, y = data_pot['Precipitation'],\n",
    "        mode ='markers', name = 'Peaks Over Threshold',\n",
    "    )\n",
    ")\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=0, x1=1, xref='paper',\n",
    "    y0=th,  y1=th, yref='y',\n",
    "    line=dict(\n",
    "        color=\"gray\",\n",
    "        dash=\"dash\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"time\",\n",
    "    yaxis_title = \"Precipitation (mm/d)\",\n",
    "    yaxis=dict(rangemode='nonnegative')\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data visualization - Daily and POT precipitation <a class=\"anchor\" id=\"22\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annual maxima series \n",
    "var_max = data_pot['Precipitation'].values[:] \n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace( \n",
    "    go.Histogram(x = data['Precipitation'], nbinsx = 30, histnorm='probability density', name='Daily')\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=var_max, nbinsx = 50, histnorm='probability density', name='POT')\n",
    ")\n",
    "\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"x\",\n",
    "    yaxis_title = \"P(x)\",\n",
    "    title = 'Probability Density Functions',\n",
    "    showlegend=True, \n",
    "    barmode='overlay'\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit POT Frequency and Intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Fit POT Frequency to Poisson disribution"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, c =np.unique(ix_hydro_pot, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of events each year (for hydrologic year)\n",
    "_, y_events = np.unique(ix_hydro_pot, return_counts=True)\n",
    "\n",
    "# get frequency\n",
    "N, freq = np.unique(y_events, return_counts=True)\n",
    "\n",
    "# optimize poisson lambda parameter\n",
    "params = np.mean(y_events)\n",
    "print('lambda Poisson : {0}'.format(np.float(params)))\n",
    "\n",
    "# freeze poisson distribution\n",
    "rv_poi = poisson(params)\n",
    "\n",
    "# generate some values from poisson to plot\n",
    "x = np.arange(rv_poi.ppf(0), rv_poi.ppf(0.999))\n",
    "y = rv_poi.pmf(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot POISSON PMF vs data frequency histogram\n",
    "print(freq)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=y_events, histnorm='probability density', name='Historical'))\n",
    "fig.add_trace(go.Bar(x=x, y=y, name='PMF'))\n",
    "\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"x\",\n",
    "    yaxis_title = \"P(x)\",\n",
    "    title = 'Poisson Probability Mass Function',\n",
    "    yaxis=dict(rangemode='nonnegative')\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate some values for this Poisson\n",
    "size_sim = 1000\n",
    "var_sim = rv_poi.rvs(size=size_sim)\n",
    "\n",
    "# Plot POI pdf vs simulated data\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=var_sim, histnorm='probability density', name='Simulation'))\n",
    "fig.add_trace(go.Bar(x=x, y=y, name='PDF'))\n",
    "\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"x\",\n",
    "    yaxis_title = \"P(x)\",\n",
    "    title = 'Poisson Probability Mass Function',\n",
    "    yaxis=dict(rangemode='nonnegative')\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Fit POT Intensity to Generalized Pareto distribution   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get event max intensity (for hydrologic year)\n",
    "imax = data_pot.groupby(by=[ix_hydro_pot]).max()\n",
    "intensity = data_pot.values - th\n",
    "\n",
    "# fit data to GPD\n",
    "shape, loc, scale = genpareto.fit(intensity, floc=0)\n",
    "print(shape, loc, scale)\n",
    "\n",
    "# negative loglikelihood\n",
    "nLogL = genpareto.nnlf((shape, loc, scale), intensity)\n",
    "\n",
    "# GPD parameters\n",
    "theta = (shape, loc, scale)\n",
    "\n",
    "# freeze GPD with parameters, get GPD PDF\n",
    "rv_gpd = genpareto(shape, loc, scale)  \n",
    "x = np.linspace(rv_gpd.ppf(0.001), rv_gpd.ppf(0.999), 1000)\n",
    "y = rv_gpd.pdf(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot GPD PDF vs data probability density histogram\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y, mode='lines', name='PDF', marker_color='black'))\n",
    "fig.add_trace(go.Histogram(x=intensity.reshape(-1), nbinsx = 100, histnorm='probability density', name='Historical'))\n",
    "\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"x\",\n",
    "    yaxis_title = \"P(x)\",\n",
    "    title = 'GPD Probability Density Function',\n",
    "    yaxis=dict(rangemode='nonnegative')\n",
    ")\n",
    "fig.update_xaxes(range=[0, x.max()])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate some values for this GPD\n",
    "size_sim = 1000\n",
    "var_sim = rv_gpd.rvs(size=size_sim)\n",
    "\n",
    "# Plot POI pdf vs simulated data\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y, mode='lines', name='PDF', marker_color='black'))\n",
    "fig.add_trace(go.Histogram(x=var_sim, nbinsx= 100, histnorm='probability density', name='Simulation'))\n",
    "\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"x\",\n",
    "    yaxis_title = \"P(x)\",\n",
    "    title = 'Generalized Pareto Probability Mass Function',\n",
    "    yaxis=dict(rangemode='nonnegative')\n",
    ")\n",
    "fig.update_xaxes(range=[0, x.max()])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulate Precipitation Extremes <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Use Frequency and Intensity distributions (Poisson and Generalized Pareto) to generate Precipitation Extremes <a class=\"anchor\" id=\"41\"></a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# years of Hs extremes to simulate\n",
    "n_sims = 1000\n",
    "years_sim = 100 \n",
    "\n",
    "ds_sim = xr.Dataset()\n",
    "\n",
    "for c, ts in enumerate(range(n_sims)):\n",
    "    \n",
    "    sys.stdout.write('Simulation {0} from {1}\\r'.format(c, len(range(n_sims))))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # empty array to storage annual maximas\n",
    "    annual_max = []\n",
    "\n",
    "    # get number of extreme events for each year from POI frequency distribution\n",
    "    sim_n_events_year = rv_poi.rvs(size=years_sim)\n",
    "    \n",
    "    # simulate a large data sample\n",
    "    size = int(params * 2 * years_sim)\n",
    "    intensity_events = genpareto.rvs(shape, loc=0, scale=scale, size=size)\n",
    "    \n",
    "    # for each year, \n",
    "    for y in range(years_sim):\n",
    "\n",
    "        # simulate intensity from GPD intensity distribution, for all extreme events\n",
    "        n_events = sim_n_events_year[y]\n",
    "\n",
    "        # find annual maxima\n",
    "        if n_events > 0:\n",
    "            \n",
    "            # select number of events\n",
    "            events = intensity_events[0:n_events]\n",
    "            intensity_events = intensity_events[n_events:]\n",
    "\n",
    "            annual_max.append(th + events.max())\n",
    "            \n",
    "        else: annual_max.append(th)\n",
    "\n",
    "    # Simulated Hs Extremes\n",
    "    sim_extremes = pd.DataFrame({'hs' : annual_max})\n",
    "    sim_extremes.index.name = 'year'\n",
    "    sim_extremes = sim_extremes.to_xarray().assign_coords(sim=c).expand_dims('sim')\n",
    "\n",
    "    ds_sim = xr.merge([sim_extremes, ds_sim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_events = rv_poi.rvs(size=1)\n",
    "n_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years of Hs extremes to simulate\n",
    "n_sims = 1000\n",
    "years_sim = 100 \n",
    "\n",
    "ds_sim = xr.Dataset()\n",
    "\n",
    "for c, ts in enumerate(range(n_sims)):\n",
    "    \n",
    "    sys.stdout.write('Simulation {0} from {1}\\r'.format(c, len(range(n_sims))))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # empty array to storage annual maximas\n",
    "    annual_max = []\n",
    "    \n",
    "    for y in range(years_sim):\n",
    "        \n",
    "        n_events = rv_poi.rvs(size=1) #one random value\n",
    "        events = genpareto.rvs(shape, loc=0, scale=scale, size=n_events)\n",
    "        \n",
    "        if n_events >0:\n",
    "            annual_max.append(np.nanmax(events) + th)\n",
    "        else:\n",
    "            annual_max.append(th)\n",
    "\n",
    "    # Simulated Hs Extremes\n",
    "    sim_extremes = pd.DataFrame({'hs' : annual_max})\n",
    "    sim_extremes.index.name = 'year'\n",
    "    sim_extremes = sim_extremes.to_xarray().assign_coords(sim=c).expand_dims('sim')\n",
    "\n",
    "    ds_sim = xr.merge([sim_extremes, ds_sim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Plot return period "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux func for calculating rp time\n",
    "def t_rp(time_y):\n",
    "    ny = len(time_y)\n",
    "    return np.array([1/(1-(n/(ny+1))) for n in np.arange(1,ny+1)])\n",
    "\n",
    "# historical rp time and sorted annual maxima\n",
    "trp_hist = t_rp(imax.index)\n",
    "trp_hist_val = np.sort(imax['Precipitation'])\n",
    "\n",
    "# simulation rp time and sorted annual maxima\n",
    "trp_sim = t_rp(ds_sim.year.values)\n",
    "trp_sim_val = np.sort(ds_sim.hs.values)\n",
    "\n",
    "# calculate simulation maxima percentiles\n",
    "p95 = np.nanpercentile(trp_sim_val, 100-5/2.0, axis=0,)\n",
    "p50 = np.nanpercentile(trp_sim_val, 50, axis=0,)\n",
    "p05 = np.nanpercentile(trp_sim_val, 5/2.0, axis=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot return period\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=trp_sim, y=p95, mode='lines', name='P95', marker_color='mediumturquoise'))\n",
    "fig.add_trace(go.Scatter(x=trp_sim, y=p05, mode='lines', name='P05', marker_color='mediumturquoise',  fill='tonexty', fillcolor='rgba(0, 181, 204, 0.10)'))\n",
    "fig.add_trace(go.Scatter(x=trp_sim, y=p50, mode='lines', name='P50', marker_color='black'))\n",
    "fig.add_trace(go.Scatter(x=trp_hist, y=trp_hist_val, mode='markers', name='Hist', marker_color='red'))\n",
    "\n",
    "\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"Return Period (years)\",\n",
    "    yaxis_title = \"Precipitation (mm/d)\",\n",
    "    title = 'Annual Maxima',\n",
    "    width=400*2.5, height=300*2.5\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot return period\n",
    "\n",
    "p_max = np.nanmax(trp_sim_val, axis=0)\n",
    "p_min = np.nanmin(trp_sim_val, axis=0)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=trp_sim, y=p_max, mode='lines', name='Max', marker_color='plum'))\n",
    "fig.add_trace(go.Scatter(x=trp_sim, y=p_min, mode='lines', name='Min', marker_color='plum',  fill='tonexty', fillcolor='rgba(249, 222, 222, 0.80)'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=trp_sim, y=p95, mode='lines', name='P95', marker_color='mediumturquoise'))\n",
    "fig.add_trace(go.Scatter(x=trp_sim, y=p05, mode='lines', name='P05', marker_color='mediumturquoise',  fill='tonexty', fillcolor = 'rgba(0, 181, 204, 0.20)'))\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=trp_sim, y=p50, mode='lines', name='P50', marker_color='black'))\n",
    "fig.add_trace(go.Scatter(x=trp_hist, y=trp_hist_val, mode='markers', name='Hist', marker_color='red'))\n",
    "\n",
    "\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"Return Period (years)\",\n",
    "    yaxis_title = \"Precipitation (mm/d)\",\n",
    "    title = 'Annual Maxima',\n",
    "    width=400*2.5, height=300*2.5\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
