{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peaks Over Threshold (POT) - Poisson & Generalized Pareto distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waves database - Significant Wave Height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. Input Hs](#1)\n",
    "\t* [1.1. Load Dataset](#11)  \n",
    "\t* [1.2. Data Visualization: Time Series](#12)     \n",
    "\t* [1.3. Data Visualization: Histograms](#13)     \n",
    "    \n",
    "* [2. Peaks Over Threshold (POT)](#2)\n",
    "\t* [2.1. Calculate POT](#21)\n",
    "    * [2.2. Data visualization - Hourly and POT Hs](#22)\n",
    "\n",
    "* [3. Fit POT Frequency and Intensity](#3)\n",
    "\t* [3.1 Fit POT Frequency to Poisson disribution](#31)\n",
    "\t* [3.2 Fit POT Intensity to Generalized Pareto disribution](#32)\n",
    "    \n",
    "* [4. Simulate Precipitation Extremes](#4)\n",
    "\t* [4.1. Use Frequency and Intensity distributions (Poisson and Generalized Pareto) to generate Hs Extremes](#41)\n",
    "    * [4.2. Plot return period](#42)\n",
    "    \n",
    "<hr size=\"5\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import sys \n",
    "\n",
    "# arrays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "from numpy.random import multivariate_normal\n",
    "from scipy.stats import poisson, genpareto, genextreme\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Input Hs <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load Dataset <a class=\"anchor\" id=\"11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "p_db = op.join(os.getcwd(),'..','..','data','Waves')\n",
    "\n",
    "# read database precipitation (xls file)\n",
    "p_dat = op.join(p_db, 'cantabria_CSIRO.mat')\n",
    "\n",
    "data_mat = loadmat(p_dat)\n",
    "data_raw = pd.DataFrame(\n",
    "    {\n",
    "        'hs':data_mat['data']['hs'][0][0].squeeze(),\n",
    "        'year':data_mat['data']['year'][0][0].squeeze(),\n",
    "        'month':data_mat['data']['month'][0][0].squeeze(),\n",
    "        'day':data_mat['data']['day'][0][0].squeeze(),\n",
    "        'hour':data_mat['data']['hour'][0][0].squeeze(),\n",
    "    }\n",
    ")\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'time': pd.to_datetime(data_raw[['year', 'month', 'day', 'hour']]),\n",
    "    'hs': data_raw['hs'].squeeze()}\n",
    ")\n",
    "data.set_index('time', inplace=True)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data Visualization: Time Series <a class=\"anchor\" id=\"12\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Data Visualization - Histograms <a class=\"anchor\" id=\"13\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=['Count', 'Probability Density'],\n",
    ")\n",
    "fig.append_trace(\n",
    "    go.Histogram(x = data['hs'], nbinsx = 30), \n",
    "    1, 1,\n",
    ")\n",
    "fig.append_trace( \n",
    "    go.Histogram(x = data['hs'], nbinsx = 30, histnorm='probability density'), \n",
    "    1, 2\n",
    ")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Peaks Over Threshold (POT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Calculate POT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold \n",
    "th = np.percentile(data.hs, 98) \n",
    "ie = 5   # days between independent peaks\n",
    "\n",
    "# Calculate data over threshold\n",
    "data_pot = data.loc[data['hs'] >= th]\n",
    "\n",
    "# Days between consecutive events\n",
    "ix_space = np.diff(data_pot.index).astype('timedelta64[h]').astype(int)\n",
    "ix_space = list(ix_space) + [ie] # include last event\n",
    "\n",
    "# Get independent peaks\n",
    "idx = []\n",
    "for nt in np.where(ix_space)[0]:\n",
    "    day = data_pot.index[nt]\n",
    "    rangeday = np.arange(day-datetime.timedelta(days=ie), day+datetime.timedelta(days=ie), datetime.timedelta(hours=1))\n",
    "    if data_pot.iloc[nt].values == np.max(data.loc[rangeday]).values:\n",
    "        idx.append(nt)\n",
    "\n",
    "data_pot = data_pot.iloc[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precipitation extreme time series\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = data.index, y = data['hs'],\n",
    "        mode ='lines', name = 'Historical Hs',\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = data_pot.index, y = data_pot['hs'],\n",
    "        mode ='markers', name = 'Peaks Over Threshold',\n",
    "    )\n",
    ")\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=0, x1=1, xref='paper',\n",
    "    y0=th,  y1=th, yref='y',\n",
    "    line=dict(\n",
    "        color=\"gray\",\n",
    "        dash=\"dash\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"time\",\n",
    "    yaxis_title = \"Hs (m)\",\n",
    "    yaxis=dict(rangemode='nonnegative')\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data visualization - Hourly and POT precipitation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extreme series \n",
    "var_max = data_pot['hs'].values[:] \n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace( \n",
    "    go.Histogram(x = data['hs'],  nbinsx = 100, histnorm='probability density', name='Hourly Hs')\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=var_max,  nbinsx = 100, histnorm='probability density', name='Peaks Over Threshold')\n",
    ")\n",
    "\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"x\",\n",
    "    yaxis_title = \"P(x)\",\n",
    "    title = 'Probability Density Functions',\n",
    "    showlegend=True, \n",
    "    barmode='overlay'\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit POT Frequency and Intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Fit POT Frequency to Poisson disribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of events each year \n",
    "y_events = data_pot.groupby(by=[data_pot.index.year]).count().hs.values\n",
    "\n",
    "# get frequency\n",
    "N, freq = np.unique(y_events, return_counts=True)\n",
    "\n",
    "# optimize poisson lambda parameter\n",
    "params = np.mean(y_events)\n",
    "print('lambda Poisson : {0}'.format(np.float(params)))\n",
    "\n",
    "# freeze poisson distribution\n",
    "rv_poi = poisson(params)\n",
    "\n",
    "# generate some values from poisson to plot\n",
    "x = np.arange(rv_poi.ppf(0), rv_poi.ppf(0.999))\n",
    "y = rv_poi.pmf(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot POISSON PMF vs data frequency histogram\n",
    "print(freq)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=y_events, histnorm='probability density', name='Historical Hs'))\n",
    "fig.add_trace(go.Bar(x=x, y=y, name='PMF'))\n",
    "\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"x\",\n",
    "    yaxis_title = \"P(x)\",\n",
    "    title = 'Poisson Probability Mass Function',\n",
    "    yaxis=dict(rangemode='nonnegative')\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate some values for this Poisson\n",
    "size_sim = 1000\n",
    "var_sim = rv_poi.rvs(size=size_sim)\n",
    "\n",
    "# Plot POI pdf vs simulated data\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=var_sim, histnorm='probability density', name='Simulation Hs'))\n",
    "fig.add_trace(go.Bar(x=x, y=y, name='PMF'))\n",
    "\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"x\",\n",
    "    yaxis_title = \"P(x)\",\n",
    "    title = 'Poisson Probability Mass Function',\n",
    "    yaxis=dict(rangemode='nonnegative')\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Fit POT Intensity to Generalized Pareto disribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get event max intensity (for hydrologic year)\n",
    "imax = data_pot.groupby(by=[data_pot.index.year]).max()\n",
    "intensity = data_pot.values - th\n",
    "\n",
    "# fit data to GPD\n",
    "shape, loc, scale = genpareto.fit(intensity, floc=0)\n",
    "print(shape, loc, scale)\n",
    "\n",
    "# negative loglikelihood\n",
    "nLogL = genpareto.nnlf((shape, loc, scale), intensity)\n",
    "\n",
    "# GPD parameters\n",
    "theta = (shape, loc, scale)\n",
    "\n",
    "# freeze GPD with parameters, get GPD PDF\n",
    "rv_gpd = genpareto(shape, loc, scale)  \n",
    "x = np.linspace(rv_gpd.ppf(0), rv_gpd.ppf(1), 1000)\n",
    "y = rv_gpd.pdf(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot GPD PDF vs data probability density histogram\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y, mode='lines', name='PDF', marker_color='black'))\n",
    "fig.add_trace(go.Histogram(x=intensity.reshape(-1), nbinsx=100,histnorm='probability density', name='Historical'))\n",
    "\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"x\",\n",
    "    yaxis_title = \"P(x)\",\n",
    "    title = 'GPD Probability Density Function',\n",
    "    yaxis=dict(rangemode='nonnegative')\n",
    ")\n",
    "fig.update_xaxes(range=[0, x.max()])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate some values for this GPD\n",
    "var_sim = rv_gpd.rvs(size=size_sim)\n",
    "\n",
    "# Plot POI pdf vs simulated data\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y, mode='lines', name='PDF', marker_color='black'))\n",
    "fig.add_trace(go.Histogram(x=var_sim, histnorm='probability density', name='Simulation'))\n",
    "\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"x\",\n",
    "    yaxis_title = \"P(x)\",\n",
    "    title = 'Generalized Pareto Probability Mass Function',\n",
    "    yaxis=dict(rangemode='nonnegative')\n",
    ")\n",
    "fig.update_xaxes(range=[0, x.max()])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulate Hs Extremes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Use Frequency and Intensity distributions (Poisson and Generalized Pareto) to generate Hs Extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years of Hs extremes to simulate\n",
    "n_sims = 1000\n",
    "years_sim = 100 \n",
    "\n",
    "ds_sim = xr.Dataset()\n",
    "\n",
    "for c, ts in enumerate(range(n_sims)):\n",
    "    \n",
    "    sys.stdout.write('Simulation {0} from {1}\\r'.format(c, len(range(n_sims))))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # empty array to storage annual maximas\n",
    "    annual_max = []\n",
    "    \n",
    "    for y in range(years_sim):\n",
    "        \n",
    "        n_events = rv_poi.rvs(size=1) #one random value\n",
    "        events = genpareto.rvs(shape, loc=0, scale=scale, size=n_events)\n",
    "        \n",
    "        if n_events >0:\n",
    "            annual_max.append(np.nanmax(events) + th)\n",
    "        else:\n",
    "            annual_max.append(th)\n",
    "\n",
    "    # Simulated Hs Extremes\n",
    "    sim_extremes = pd.DataFrame({'hs' : annual_max})\n",
    "    sim_extremes.index.name = 'year'\n",
    "    sim_extremes = sim_extremes.to_xarray().assign_coords(sim=c).expand_dims('sim')\n",
    "\n",
    "    ds_sim = xr.merge([sim_extremes, ds_sim])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Plot return period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux func for calculating rp time\n",
    "def t_rp(time_y):\n",
    "    ny = len(time_y)\n",
    "    return np.array([1/(1-(n/(ny+1))) for n in np.arange(1,ny+1)])\n",
    "\n",
    "# historical rp time and sorted annual maxima\n",
    "trp_hist = t_rp(imax.index)\n",
    "trp_hist_val = np.sort(imax['hs'])\n",
    "\n",
    "# simulation rp time and sorted annual maxima\n",
    "trp_sim = t_rp(ds_sim.year.values)\n",
    "trp_sim_val = np.sort(ds_sim.hs.values)\n",
    "\n",
    "# calculate simulation maxima percentiles\n",
    "p95 = np.nanpercentile(trp_sim_val, 100-5/2.0, axis=0,)\n",
    "p50 = np.nanpercentile(trp_sim_val, 50, axis=0,)\n",
    "p05 = np.nanpercentile(trp_sim_val, 5/2.0, axis=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot return period\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=trp_sim, y=p95, mode='lines', name='P95', marker_color='mediumturquoise'))\n",
    "fig.add_trace(go.Scatter(x=trp_sim, y=p05, mode='lines', name='P05', marker_color='mediumturquoise',  fill='tonexty', fillcolor='rgba(0, 181, 204, 0.10)'))\n",
    "fig.add_trace(go.Scatter(x=trp_sim, y=p50, mode='lines', name='P50', marker_color='black'))\n",
    "fig.add_trace(go.Scatter(x=trp_hist, y=trp_hist_val, mode='markers', name='Hist', marker_color='red'))\n",
    "\n",
    "\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.update_layout(    \n",
    "    xaxis_title = \"Return Period (years)\",\n",
    "    yaxis_title = \"Hs (m)\",\n",
    "    title = 'POT',\n",
    "    width=400*2.5, height=300*2.5\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
